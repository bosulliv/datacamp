---
title: "R Notebook"
output: html_notebook
---

# Chapter 4

```{r}
# data prep
sparrow <- readRDS(gzcon(url("https://assets.datacamp.com/production/course_3851/datasets/sparrow.rds")))
```


```{r}
# sparrow is in the workspace
summary(sparrow)

# Create the survived column
sparrow$survived <- ifelse(sparrow$status == "Survived", TRUE, FALSE)

# Create the formula
(fmla <- as.formula(survived ~ total_length + weight + humerus))

# Fit the logistic regression model
sparrow_model <- glm(fmla, data = sparrow, family = "binomial")

# Call summary
summary(sparrow_model)

# Call glance
(perf <- glance(sparrow_model))

# Calculate pseudo-R-squared
(pseudoR2 <- glance(sparrow_model) %>% summarise(pR2 = 1 - deviance/null.deviance))
```

```{r}
# sparrow is in the workspace
summary(sparrow)

# sparrow_model is in the workspace
summary(sparrow_model)

# Make predictions
sparrow$pred <- predict(sparrow_model, type = "response")

# Look at gain curve
GainCurvePlot(sparrow, "pred", "survived", "sparrow survival model")
```

# Penny Drop

Bingo - I understand the gain curve!

Group by the real survived rate - so that all values that are true are first, followed by all rows that are false. Then move along each row and check if the prediction is equal to teh real value. If it is you go up, if it isn't you move along. If the predictions are perfect then we choose to follow a slope. This slope is the ratio of true values to total values. 

For sparrows:

   $$slope = \frac {\sum(survived == TRUE)}{nrow(sparrow)}$$
  $$slope = \frac {51}{87} = 0.586$$

We could approximate the sparrow gain curve with this data - I've made three 'mistakes' in set of 10 rows. Notice that it is sorted by the actual column. The slope will go 'up' when the values are true, and across when they are false.

| act  | pred   |
|------|--------|
|    1 |   1    |   
|    1 |   1    |
|    1 |   1    |
|    1 |   0    |
|    1 |   1    |
|    1 |   0    |
|    0 |   0    |
|    0 |   1    |
|    0 |   0    |
|    0 |   0    |

```{r}
# prep data
load(gzcon(url("https://assets.datacamp.com/production/course_3851/datasets/Bikes.RData")))

# > cat(vars,sep='","')
vars <- c("hr","holiday","workingday","weathersit","temp","atemp","hum","windspeed")

outcome <- "cnt"
```


```{r}
# bikesJuly is in the workspace
str(bikesJuly)

# The outcome column
outcome 

# The inputs to use
vars 

# Create the formula string for bikes rented as a function of the inputs
(fmla <- paste(outcome, "~", paste(vars, collapse = " + ")))

# Calculate the mean and variance of the outcome
(mean_bikes <- mean(bikesJuly$cnt))
(var_bikes <- var(bikesJuly$cnt))

# Fit the model
bike_model <- glm(fmla, data = bikesJuly, family = "quasipoisson")

# Call glance
(perf <- glance(bike_model))

# Calculate pseudo-R-squared
(pseudoR2 <- glance(bike_model) %>% summarise(pR2 = 1 - deviance/null.deviance))
```

```{r}
# bikesAugust is in the workspace
str(bikesAugust)

# bike_model is in the workspace
summary(bike_model)

# Make predictions on August data
bikesAugust$pred  <- predict(bike_model, newdata = bikesAugust, type = "response")

# Calculate the RMSE
bikesAugust %>% 
  mutate(residual = pred - cnt) %>%
  summarize(rmse  = sqrt(mean(residual^2)))

# Plot predictions vs cnt (pred on x-axis)
ggplot(bikesAugust, aes(x = pred, y = cnt)) +
  geom_point() + 
  geom_abline(color = "darkblue")
```

```{r}
# Plot predictions and cnt by date/time
bikesAugust %>% 
  # set start to 0, convert unit to days
  mutate(instant = (instant - min(instant))/24) %>%  
  # gather cnt and pred into a value column
  gather(key = valuetype, value = value, cnt, pred) %>%
  filter(instant < 14) %>% # restric to first 14 days
  # plot value by instant
  ggplot(aes(x = instant, y = value, color = valuetype, linetype = valuetype)) + 
  geom_point() + 
  geom_line() + 
  scale_x_continuous("Day", breaks = 0:14, labels = 0:14) + 
  scale_color_brewer(palette = "Dark2") + 
  ggtitle("Predicted August bike rentals, Quasipoisson model")
```

# Generalised Additive Models (GAMs)

```{r}
library(mgcv)
```

When using gam() to model outcome as an additive function of the inputs, you can use the s() function inside formulas to designate that you want use a spline to model the non-linear relationship of a continuous variable to the outcome.

Suppose that you want to predict how much weight (Wtloss) a dieter will lose over a 2-year diet plan as a function of:

    * Diet type (categorical)
    * Sex (categorical)
    * Age at beginning of diet (continuous)
    * BMI (body mass index) at beginning of diet (continuous)
    * You do not want to assume that any of the relationships are linear.

Which is the most appropriate formula?

    Wtloss ~ Diet + Sex + s(Age) + s(BMI)

Suppose that in the diet problem from the previous exercise, you now also want to take into account

      * the dieter's resting metabolic rate (BMR -- continuous) and
      * the dieter's average number hours of aerobic exercise per day (E -- continuous) at the beginning of the study.

You have reason to believe that the relationship between BMR and weight loss is linear (and you want to model it that way), but not necessarily the relationship between aerobic exercise and weight loss.

Which is the most appropriate formula?

    Wtloss ~ Diet + Sex + s(Age) + s(BMI) + BMR + s(E)

```{r}
# prep data
load(gzcon(url("https://assets.datacamp.com/production/course_3851/datasets/Soybean.RData")))

model.lin <- lm(weight ~ Time, data = soybean_train)
```

```{r}
# soybean_train is in the workspace
summary(soybean_train)

# Plot weight vs Time (Time on x axis)
ggplot(soybean_train, aes(x = Time, y = weight)) + 
  geom_point()

# Load the package mgcv
library(mgcv)

# Create the formula 
(fmla.gam <- as.formula(weight ~ s(Time)) )

# Fit the GAM Model
model.gam <- gam(fmla.gam, family = "gaussian", data = soybean_train)

# Call summary() on model.lin and look for R-squared
summary(model.lin)

# Call summary() on model.gam and look for R-squared
summary(model.gam)

# Call plot() on model.gam
plot(model.gam)
```

```{r}
# soybean_test is in the workspace
summary(soybean_test)

# Get predictions from linear model
soybean_test$pred.lin <- predict(model.lin, newdata = soybean_test)

# Get predictions from gam model
soybean_test$pred.gam <- as.numeric(predict(model.gam, newdata = soybean_test))

# Gather the predictions into a "long" dataset
soybean_long <- soybean_test %>%
  gather(key = modeltype, value = pred, pred.lin, pred.gam)

# Calculate the rmse
soybean_long %>%
  mutate(residual = weight - pred) %>%     # residuals
  group_by(modeltype) %>%                  # group by modeltype
  summarize(rmse = sqrt(mean(residual^2))) # calculate the RMSE

# Compare the predictions against actual weights on the test data
soybean_long %>%
  ggplot(aes(x = Time)) +                          # the column for the x axis
  geom_point(aes(y = weight)) +                    # the y-column for the scatterplot
  geom_point(aes(y = pred, color = modeltype)) +   # the y-column for the point-and-line plot
  geom_line(aes(y = pred, color = modeltype, linetype = modeltype)) + # the y-column for the point-and-line plot
  scale_color_brewer(palette = "Dark2")
  
```

